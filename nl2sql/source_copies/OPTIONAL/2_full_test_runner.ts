// src/backend/sql/promptEval/fullTest.ts

import OpenAI from "openai";
import Groq from "groq-sdk";
import dotenv from 'dotenv';
import { SupabaseClient, PostgrestError } from '@supabase/supabase-js'; // Import PostgrestError

// Imports from existing project files (adjust paths as necessary)
import { MedTemplate } from './medTemplateLists'; //
import { evaluateClarity, ClarityResult } from './clarityEvaluator'; //
import { callAI, getDevForModelName } from './ai';
import { callOpenAI } from './ai';
import { getOrganisationsTableSystemPrompt } from './sysPrompts';
import { getMainTablesSystemPrompt } from './sysPrompts';
import { supabaseExecuteSQL, getSupabaseClient, SqlExecutionResult } from '../supabase/supabaseQuery'; //
// Potentially import evaluateResults from './evaluator' if final accuracy scoring is needed later

let doEvaluatePromptClarity = false;
let useClarifiedPrompt = true;
let useAlternatePrompts = true; // if false will only use nl, not nl_focused or nl_simple

dotenv.config(); // Load environment variables

const supabase: SupabaseClient = getSupabaseClient(); //

// Get the system prompt
const sqlSystemPrompt = getOrganisationsTableSystemPrompt(); //
// Get the main tables system prompt
const mainTablesSystemPrompt = getMainTablesSystemPrompt(); //

/* Just for easy reference, this is stored in clarityEvaluator.ts 

export interface ClarityResult {
  clarity_score: number; // Score from 1-10
  status: 'CLEAR' | 'NEEDS_CLARIFICATION'; // Status based on score
  clarified_prompt: string | null; // The refined prompt if status is CLEAR, otherwise null
  options: string[] | null; // Array of 3 options if status is NEEDS_CLARIFICATION, otherwise null
  message: string | null; // Optional message from the agent
  reasoning: string | null; // explanation of the score, and what is lacking, vague or ambiguous and needs improvement
  model_name: string; // The model used for clarity evaluation
}
*/

/*  Stores a SQL Query - a result of an NL-to-SQL operation.  */
export interface GenSQLAndQueryResult {
  genSQL: string; // The generated SQL query
  resultData?: unknown[] | null; // 
  error?: PostgrestError | Error | null; //
}

/**
 * Interface to hold the consolidated results for one input MedTemplate test run.
 */
interface FullTestResult {
  inputTemplate: MedTemplate;
  clarityResults: Map<string, ClarityResult>; // e.g <nl_simple, ClarityResult> (Keyed by 'nl', 'nl_focused', 'nl_simple' - Stores the clarity analysis results for each type of prompt (nl, nl_focused, nl_simple), using a Map for efficient retrieval.
  nl_genSQL: GenSQLAndQueryResult | null;              // SQL generated by the 'nl' prompt. Can be null if the translation fails or is not performed.
  nlFocused_genSQL: GenSQLAndQueryResult | null;       // SQL generated by the 'nl_focused' prompt. Can be null 
  nlSimple_genSQL: GenSQLAndQueryResult | null;        // SQL generated by the 'nl_simple' prompt. Can be null
  nlSimpleClarified_genSQL: GenSQLAndQueryResult | null; // Stores clarified version of the 'nl_simple' prompt. Can be null
  errors: string[];                           // To collect any processing errors - An array to collect any errors that occur during the test execution, providing a comprehensive log of issues encountered.
  sqlModelName: string; // The model used for SQL generation
  clarityModelName: string; // The model used for clarity evaluation
}


//=====================================================================================================
//                          nl2sqlWrapper        Main nl2sql call
//=====================================================================================================
/**
 * Wraps the NL-to-SQL generation and execution logic.
 * @param promptText - The natural language prompt.
 * @param modelName - The Groq model name (e.g., "llama3-8b").
 * @returns A Promise resolving to a GenSQLAndQueryResult object:
  GenSQLAndQueryResult {
    genSQL: string; 
    resultData:
    error:
    }
}
 * @async
 */
async function nl2sqlWrapper(modelName: string = "llama3-8b-8192", promptText: string, systemPrompt: string, options: {
  temperature?: number;
  responseFormat?: { type: string };
} = {}): Promise<GenSQLAndQueryResult> {
  console.log(`nl2sqlWrapper processing prompt: "${promptText}" using model: ${modelName}`);

  const aiDev = getDevForModelName(modelName);

  let sqlQuery = '';
  let queryResult: unknown[] | null = null;
  let queryError: PostgrestError | Error | null = null;

  //==============================================================
  //          Generate SQL Query from a nl2sql call
  //==============================================================

  try {
    if (aiDev === 'openai') {
      sqlQuery = await callOpenAI(modelName, promptText, systemPrompt, options); //
    }
    /*else if (aiDev === 'groq') {
      sqlQuery = await callGroq(model, promptText, systemPrompt, options); //
    }
    else if (aiDev === 'google') {
      sqlQuery = await callGoogle(model, promptText, systemPrompt, options); //
    }
    else if (aiDev === 'anthropic') {
      sqlQuery = await callAnthropic(model, promptText, systemPrompt, options); //
    }*/
    console.log(`Generated SQL: ${sqlQuery}`);

    //==============================================================
    //                 Execute generated SQL Query
    //==============================================================

    console.log(`--- Attempting Supabase query for: "${promptText}" ---`);
    try {
      //==========  Execute SQL using Supabase  =============
      const result = await supabaseExecuteSQL(sqlQuery); //

      queryResult = result.queryResultData as unknown[] | null;
      queryError = result.queryResultError;
      if (result.queryResultError) {
        console.error(`SQL execution failed for "${promptText}":`, result.queryResultError.message);
      } else {
        console.log(`SQL execution succeeded for "${promptText}". Records: ${queryResult?.length ?? 0}`);
      }
    } catch (execError) {
      console.error(`!!! Exception during Supabase execution for "${promptText}":`, execError);
      console.error(`Attempted SQL: ${sqlQuery}`);
      queryError = execError instanceof Error ? execError : new Error(String(execError));
    } finally {
      console.log(`--- Supabase query attempt finished for: "${promptText}" ---`);
    }

  } catch (nl2sqlError) {
    console.error(`!!! Error during nl2sql generation for "${promptText}":`, nl2sqlError);
    queryError = nl2sqlError instanceof Error ? nl2sqlError : new Error(String(nl2sqlError));
    sqlQuery = 'Error generating SQL';
  }

  return {
    genSQL: sqlQuery,
    resultData: queryResult,
    error: queryError
  };
}
//=====================================================================================================
//                                  testNlPrompt calls nl2sqlWrapper
//=====================================================================================================
/**
 * (#1) Error Handling Helper: Executes nl2sqlWrapper within a try-catch block.
 * @param promptQualityType - Identifier for the prompt type (e.g., 'nl', 'nl_focused').
 * @param prompt - The natural language prompt text.
 * @param model - The SQL generation model to use.
 * @param errorsArray - Array to push error messages into.
 * @returns A Promise resolving to a PromptResult or null if an error occurred.
 * @async
 */
async function testNlPrompt(
  model: string,
  prompt: string,
  sysPrompt: string,
  promptQualityType: string,
  errorsArray: string[]
): Promise<GenSQLAndQueryResult | null> {
  try {
    console.log(`Testing ${promptQualityType}: "${prompt}"`);
    return await nl2sqlWrapper(model, prompt, sysPrompt);
  }
  catch (error: unknown) { // Catch unknown for safety
    const errorMsg = `Error in nl2sqlWrapper for ${promptQualityType}: ${error instanceof Error ? error.message : String(error)}`;
    console.error(errorMsg);
    errorsArray.push(errorMsg);
    return null;
  }
}


//=========================================================================================================================================================
//
//                            **    Main Test Loop Function     mainTestLoop()    **
//
//=========================================================================================================================================================

/**
 * Executes the full test process for a single MedTemplate case.
 * 1. Evaluates clarity for nl, nl_focused, nl_simple.   2. Runs NL-to-SQL for nl, nl_focused, nl_simple using a helper. +
 * runs NL-to-SQL for the clarified version of nl_simple (if available) using a helper.
 * @param exampleTemplate - The MedTemplate object containing the test data.
 * @param clarityModelName - The model to use for clarity evaluation (default: llama3-8b-8192).
 * @param sqlModelName - The model to use for SQL generation (default: llama3-8b).
 * @returns A Promise resolving to a FullTestExecutionResult object containing all results and errors.
 * @async
 */
export async function fullTest(
  exampleTemplate: MedTemplate,
  clarityModelName: string = "gpt-4o",
  sqlModelName: string = "gpt-4o"
): Promise<FullTestResult> {

  clarityModelName = "gpt-4o-mini";
  //sqlModelName = "gpt-4o-mini";
  //sqlModelName = "llama3-8b-8192";
  sqlModelName = "llama-3.2-3b-preview";

  // Define structure for prompts to process
  // Defines the structure for the prompts to be analyzed, creating an array of objects, where each object contains a 'key' (identifying the prompt type) and the 'prompt' (the actual natural language query).
  const promptsToAnalyze: { key: 'nl' | 'nl_focused' | 'nl_simple'; prompt: string }[] = [
    { key: 'nl', prompt: exampleTemplate.input.nl }, // Adds the 'nl' (natural language) prompt from the testCase input to the array.
    { key: 'nl_focused', prompt: exampleTemplate.input.nl_focused }, // Adds the 'nl_focused' prompt from the testCase input to the array.
    { key: 'nl_simple', prompt: exampleTemplate.input.nl_simple } // Adds the 'nl_simple' prompt from the testCase input to the array.
  ];

  // `executionResult`: An object to store the results of the test execution.
  // Initializes an object to store the results of the test execution. This object will hold the input template, clarity analysis results, NL-to-SQL translation results, and any errors encountered during the process.
  /*const executionResult: FullTestExecutionResult = {
    inputTemplate: JSON.parse(JSON.stringify(exampleTemplate)), // Deep copy input, creates a deep copy of the input `testCase` to prevent modification of the original test data during the test run.
    clarityResults: new Map<string, ClarityResult>(), // (#4) Use Map, a `Map` to store the clarity analysis results for each prompt type.  Using a `Map` provides efficient lookups and preserves the order of insertion.
    nl_genSQL: null, // Stores the result of the NL-to-SQL translation for the [nl](cci:1://file:///c:/Users/steve/JupyterPython/DatabaseProject/nl2sql/src/backend/sql/promptEval/fullTest.ts:69:0-150:1) prompt.
    nlFocused_genSQL: null, // Stores the result of the NL-to-SQL translation for the `nl_focused` prompt.
    nlSimple_genSQL: null, // Stores the result of the NL-to-SQL translation for the `nl_simple` prompt.
    nlSimpleClarified_genSQL: null, // Stores the result of the NL-to-SQL translation for the clarified version of the `nl_simple` prompt.
    errors: [], // An array to accumulate any errors encountered during the test execution.
    sqlModelName: sqlModelName,
    clarityModel: clarityModelName
  };*/

  //console.log(`\n===== Running Test Loop for: ${exampleTemplate.input.test_name} =====`);

  //==============================================================  
  //                Evaluate Prompt Clarity
  //==============================================================

  const clarityResultsMap: Map<string, ClarityResult> = new Map<string, ClarityResult>();
  if (doEvaluatePromptClarity) {
    console.log("--- Evaluating Prompt Clarity ---");
    for (const item of promptsToAnalyze) {
      try {
        console.log("-----------------------------------------------------------------")
        console.log(`** Evaluating clarity for ${item.key}: "${item.prompt}"`);

        //=======  Evaluate the clarity of the current prompt ======
        //returns a **ClarityResult** object.
        const clarityEvalResult: ClarityResult = await evaluateClarity(clarityModelName, item.prompt);

        // Store the ClarityResult object in the executionResult.clarityAnalyses Map.
        // The key for the Map is the item.key, which indicates which prompt type (nl, nl_focused, nl_simple) was analyzed.
        clarityResultsMap.set(item.key, clarityEvalResult);
      }
      catch (error: unknown) {
        // If an error occurs during the clarity evaluation, catch the error.
        const errorMsg = `Error evaluating clarity for ${item.key}: ${error instanceof Error ? error.message : String(error)}`;
        console.error(errorMsg);
        //executionResult.errors.push(errorMsg);

        // Add a placeholder/error ClarityResult to  Map to indicate an error occurred, ensures that the Map always contains a result for each prompt type, even if evaluation failed.
        clarityResultsMap.set(item.key, {
          clarity_score: 0,
          status: 'NEEDS_CLARIFICATION',
          clarified_prompt: null,
          options: null,
          message: `Error: ${error instanceof Error ? error.message : String(error)}`,
          reasoning: null, // Add reasoning if part of interface
          model_name: clarityModelName
        });
      }
    }
    console.log("Clarity evaluation complete.");
  }

  //==============================================================  
  //            Test Prompts with testNlPrompt()   x3
  //==============================================================
  console.log("\n--- Testing Original Prompts (NL-to-SQL) ---");

  const aiDev = getDevForModelName(clarityModelName);

  const options: {
    temperature?: number;
    responseFormat?: { type: string };
  } = {};

  //=================
  //   nl_simple
  //=================
  const nl_simple_prompt: string = exampleTemplate.input.nl_simple;
  let generatedSqlQuery_simple = await callAI(sqlModelName, nl_simple_prompt, mainTablesSystemPrompt, {
    temperature: options.temperature,
    response_format: options.responseFormat
  });

  //=== Execute SQL Query and get results ===
  let queryResult_simple = await supabaseExecuteSQL(generatedSqlQuery_simple); //

  const genSQLAndQueryResult_simple: GenSQLAndQueryResult = {
    genSQL: generatedSqlQuery_simple,
    resultData: queryResult_simple.queryResultData as unknown[] | null,
    error: queryResult_simple.queryResultError
  };
  //=================
  //   nl_std
  //=================
  /*const nl_std_prompt: string = exampleTemplate.input.nl;
  let generatedSqlQuery_std = await callOpenAI(sqlModelName, nl_std_prompt, mainTablesSystemPrompt, options);
  
  //=== Execute SQL Query and get results ===
  let queryResult_std = await supabaseExecuteSQL(generatedSqlQuery_std); //
  
  const genSQLAndQueryResult_std: GenSQLAndQueryResult = {
    genSQL: generatedSqlQuery_std,
    resultData: queryResult_std.data as unknown[] | null,
    error: queryResult_std.error
  };
  //=================
  //   nl_focused
  //=================
  const nl_focused_prompt: string = exampleTemplate.input.nl_focused;
  let generatedSqlQuery_focused = await callOpenAI(sqlModelName, nl_focused_prompt, mainTablesSystemPrompt, options);
  
  //=== Execute SQL Query and get results ===
  let queryResult_focused = await supabaseExecuteSQL(generatedSqlQuery_focused); //
  
  const genSQLAndQueryResult_focused: GenSQLAndQueryResult = {
    genSQL: generatedSqlQuery_focused,
    resultData: queryResult_focused.data as unknown[] | null,
    error: queryResult_focused.error
  };*/

  const genSQLAndQueryResult_std: GenSQLAndQueryResult = { genSQL: "", resultData: null, error: null };
  const genSQLAndQueryResult_focused: GenSQLAndQueryResult = { genSQL: "", resultData: null, error: null };

  //==================================================
  //          Build Full Test Result
  //==================================================
  const errors: string[] = [];
  //=== Add the sql results to the full results
  const fullTestResult: FullTestResult = BuildFullTestResult(exampleTemplate, clarityResultsMap, genSQLAndQueryResult_std, genSQLAndQueryResult_simple, genSQLAndQueryResult_focused, errors, sqlModelName, clarityModelName);



  //-----------    Test Clarified 'nl_simple' prompt   (Clarified result from ClarityResult in clarityEvaluator)  ------------


  //=====================================
  //             Print Summary
  //=====================================
  console.log(`\n***************   sSummary of Results (Clarity Model: ${clarityModelName}, SQL Model: ${sqlModelName})   ***************`);
  //console.log(`Execution Result :`, executionResult);

  console.log("Known SQL: ", exampleTemplate.input.known_sql);
  console.log("nl_simple: ", exampleTemplate.input.nl_simple);
  console.log("nl_simple_sql: ", genSQLAndQueryResult_simple);
  //console.log("clarified nl_simple: ", clarityResultsMap.get('nl_simple')?.clarified_prompt);

  console.log("\n--- End of Summary ---");


  /*if (executionResult.clarityResults.get('nl_simple')?.status === 'CLEAR' && executionResult.nlSimpleClarified_sql?.sql) {
  //if (executionResult.nlSimpleClarified_sql?.status === 'CLEAR' && executionResult.nlSimpleClarified_sql?.clarified_prompt) {
    console.log(`Testing clarified_prompt: "${nl_clarified_simple_prompt}"`);
     // (#1) Use error handling helper
    executionResult.nlSimpleClarified_sql = await testNlPrompt('nl_simple_clarified',nl_clarified_simple_prompt,sqlModel,executionResult.errors);
  } else {
    const msg = `Skipping NL-to-SQL for clarified nl_simple: Status was ${simpleClarityResult?.status ?? 'unknown'} or clarified_prompt was null.`;
    console.log(msg);
    // Optionally add info message to errors if desired: executionResult.errors.push(msg);
  }*/

  console.log(`===== Test Loop Complete for: ${exampleTemplate.input.test_name} =====\n`);
  return fullTestResult;
}
function BuildFullTestResult(exampleTemplate: MedTemplate, clarityResultsMap: Map<string, ClarityResult>,
  nlStd_info: GenSQLAndQueryResult, nlFocused_info: GenSQLAndQueryResult, nlSimple_info: GenSQLAndQueryResult,
  errors: string[] | null, sqlModelName: string, clarityModelName: string) {

  const fullTestResult: FullTestResult = {
    inputTemplate: exampleTemplate,
    clarityResults: clarityResultsMap,
    nl_genSQL: nlStd_info,
    nlFocused_genSQL: nlFocused_info,
    nlSimple_genSQL: nlSimple_info,
    nlSimpleClarified_genSQL: null,
    errors: errors ?? [],
    sqlModelName: sqlModelName,
    clarityModelName: clarityModelName
  };

  return fullTestResult;
}
